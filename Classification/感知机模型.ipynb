{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 感知机模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型：在二维空间中，找到一条直线，将所有二元类别分开；在三维或多维空间中，找到一个超平面，把所有二元类别分开。\n",
    "\n",
    "场景：数据线性可分\n",
    "\n",
    "模型定义：\n",
    "$$ y = sign(\\theta \\cdot x) $$\n",
    "其中：$ sign(x) = \\begin{cases} -1, & \\text {$ x < 0 $} \\\\ 1, & \\text{$ x \\geq 0 $} \\end{cases}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "期望使误分类的所有样本，到超平面的距离之和最小。定义损失函数为所有误分类的样本到超平面距离之和。采用保留分子法，进行简化，最终感知机模型损失函数为：\n",
    "$$ J(\\theta) = -\\sum_{x_i \\in M}y^{(i)} \\theta \\cdot x^{(i)} $$\n",
    "M: 为所有误分类点集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义所有$\\theta_0$为$1$。选择$\\theta$向量的初值和步长$\\alpha$的初值。可以将$\\theta$向量置为$0$向量，步长设置为$1$。感知机的解不唯一，初值的设定会影响$\\theta$的最终迭代结果。\n",
    "2. 在训练集里面选择一个误分类的点$(x^{(i)}, y^{(i)})$，这个点应该满足：$y^{(i)} \\theta \\cdot x^{(i)} \\leq 0$\n",
    "3. 对$\\theta$向量进行一次随机梯度下降的迭代：$ \\theta = \\theta + \\alpha y^{(i)}x^{(i)}$\n",
    "4. 检查训练集里是否还有误分类的点，如果没有，算法结束，此时的$\\theta$向量即为最终结果。如果有，继续第2步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型算法对偶形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "系数$ \\theta $每次迭代都是选择一个样本来更新，正确样本参与迭代次数为$0$，令误分类样本$j$迭代次数为$m_j$，$\\theta$向量初始值为$0$向量。则有：\n",
    "$$ \\theta = \\alpha \\sum_{j=1}^m {m_j {y^{(j)}} {x^{(j)}}} $$\n",
    "\n",
    "步长$ \\alpha $为常量，令$ \\beta_j = \\alpha m_j $，则有：\n",
    "$$ \\theta = \\sum_{j=1}^m {\\beta_j {y^{(j)}} {x^{(j)}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义内积矩阵Gram矩阵，它是一个对称矩阵。\n",
    "$$ G = [x^{(i)} \\cdot x^{(j)}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对偶形式模型算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义所有$x_0$为$1$，步长$\\alpha$初值，设置$\\beta$的初值$0$。可以将$\\alpha$设置为$1$。\n",
    "2. 计算所有样本内积形成的Gram矩阵$G$。\n",
    "3. 在训练集里面选择一个误分类的点$(x^{(i)},y^{(i)})$，这个点应该满足： $y^{(i)} \\sum_{j=1}^m \\beta_j y^{(j)} x^{(j)} \\cdot x^{(i)} \\leq 0$，在检查是否满足时可以通过查询Gram矩阵的$g_ij$的值来快速计算是否小于$0$。\n",
    "4. 对$\\beta$向量的第$i$个分量进行一次更新：$\\beta_i = \\beta_i + \\alpha$\n",
    "5. 检查训练集里是否还有误分类的点，如果没有，算法结束，此时的$\\theta$向量最终结果为下式。如果有，继续第2步。\n",
    "$$\\theta = \\sum_{j=1}^m \\beta_j y^{(j)} x^{(j)}$$\n",
    "其中$\\beta_j$为$\\beta$向量的第$j$个分量。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
