{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息论基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵度量了事物的不确定性，事物的不确定性越大，熵越大。\n",
    "\n",
    "$$ H(x) = - \\sum_{i=1}^n p_i \\log p_i $$\n",
    "\n",
    "其中，$n$为变量$x$取不同离散值的个数，$p_i$是变量$x$取值$i$的概率，$\\log$为以$2$或$e$为底的对数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个变量$x$和$y$的联合熵：\n",
    "$$ H(x, y) = - \\sum_{i=1}^n p(x_i, y_i) \\log p(x_i, y_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件熵，度量了在$y$已知下，变量$x$的不确定性：\n",
    "$$ H(x|y) = - \\sum_{i=1}^n p(x_i, y_i) \\log p(x_i | y_i) = \\sum_{j=1}^n p(y_j) H(x|y_j) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益（互信息），定义了在$y$确定后，$x$不确定性减少的程度。\n",
    "$$ I(x, y) = H(x) - H(x|y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算信息增益，选择信息增益最大的特征来建立决策树的当前节点。\n",
    "\n",
    "**示例：**\n",
    "\n",
    "假设有15个样本D，输出为0或者1。其中有9个输出为1， 6个输出为0。 样本中有个特征A，取值为A1，A2和A3。在取值为A1的样本的输出中，有3个输出为1， 2个输出为0，取值为A2的样本输出中,2个输出为1,3个输出为0， 在取值为A3的样本中，4个输出为1，1个输出为0。\n",
    "\n",
    "样本D的熵为：$ H(D) = -(\\frac{9}{15}log_2\\frac{9}{15} + \\frac{6}{15}log_2\\frac{6}{15}) = 0.971 $\n",
    "\n",
    "样本D在特征下的条件熵为：$ H(D \\mid A)=\\frac{5}{15}H(D1) + \\frac{5}{15}H(D2) + \\frac{5}{15}H(D3)\n",
    "                                = −\\frac{5}{15}(\\frac{3}{5}log_2\\frac{3}{5} + \\frac{2}{5}log_2\\frac{2}{5}) − \\frac{5}{15}(\\frac{2}{5}log_2\\frac{2}{5} + \\frac{3}{5}log_2\\frac{3}{5}) − \\frac{5}{15}(\\frac{4}{5}log_2\\frac{4}{5} + \\frac{1}{5}log_2\\frac{1}{5}) = 0.888 $　　\n",
    "\n",
    "对应的信息增益为：$ I(D,A) = H(D) - H(D \\mid A) = 0.083 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树ID3算法思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**背景**：输入的是$m$个样本，样本输出集合为$D$，每个样本有$n$个离散特征，特征集合即为$A$，输出为决策树$T$。\n",
    "\n",
    "算法的过程为：\n",
    "\n",
    "1. 初始化信息增益的阈值$\\epsilon$\n",
    "2. 判断样本是否为同一类输出$D_i$，如果是则返回单节点树$T$。标记类别为$D_i$\n",
    "3. 判断特征是否为空，如果是则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。\n",
    "4. 计算$A$中的各个特征（一共$n$个）对输出$D$的信息增益，选择信息增益最大的特征$A_g$\n",
    "5. 如果$A_g$的信息增益小于阈值$\\epsilon$，则返回单节点树$T$，标记类别为样本中输出类别$D$实例数最多的类别。\n",
    "6. 否则，按特征$A_g$的不同取值$A_{gi}$将对应的样本输出$D$分成不同的类别$D_i$。每个类别产生一个子节点。对应特征值为$A_{gi}$。返回增加了节点的数$T$。\n",
    "7. 对于所有的子节点，令$D=D_i,A=A - {A_g}$递归调用2-6步，得到子树$T_i$并返回。\n",
    "\n",
    "**节点的子节点个数取决于该节点变量的离散值个数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树ID3算法不足点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ID3没有考虑连续特征，限制了ID3的用途。\n",
    "2. ID3采用信息增益大的特征优先建立决策树节点。但相同条件下，取值较多的特征信息增益比取值较少的特征大。\n",
    "3. ID3没有考虑缺失值处理。\n",
    "4. ID3没有考虑过拟合问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
