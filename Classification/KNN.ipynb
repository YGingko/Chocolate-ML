{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既可用于分类，也可用于回归。主要区别在于最终决策方式不同，分类预测时，选择多数表决法；回归测试时，选择平均法。\n",
    "\n",
    "**KNN算法有多种实现方式，Scikit-Learn中使用了brute-force、KDTree和BallTree实现方式，另外还有BBF树、MVP树等方式**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN算法三要素\n",
    "\n",
    "- **分类决策规则**： 一般是多数表决法，或平均法。\n",
    "\n",
    "- **K值选择**：没有固定经验，一般根据样本的分布，选择一个较小的值，通过交叉验证进一步选择一个合适的K值。K值较小，意味着参与预测的训练样本较少，训练误差会很小，模型更复杂，容易过拟合；K值较大，意味着参与预测的训练样本较多，训练误差较大，模型复杂度较低，预测偏差较大。\n",
    "\n",
    "- **距离度量方式**：方式较多，但欧式距离最常用，大多数情况下都能满足需求。\n",
    "\n",
    "\n",
    "欧式距离：\n",
    "$$ D(x, y) = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\cdots + (x_n - y_n)^2} = \\sqrt{\\sum_{i=1}^n {(x_i - y_i)^2}} $$\n",
    "\n",
    "曼哈顿距离：\n",
    "$$ D(x, y) = \\mid x_1 - y_1 \\mid + \\mid x_2 - y_2 \\mid + \\cdots + \\mid x_n - y_n \\mid = \\sum_{i=1}^n {\\mid x_i - y_i \\mid} $$\n",
    "\n",
    "闵科夫斯基距离（Minkowski Distance）：\n",
    "$$ D(x, y) = \\sqrt[p]{(\\mid x_1 - y_1 \\mid)^p + (\\mid x_2 - y_2 \\mid)^p + \\cdots + (\\mid x_n - y_n \\mid)^p} = \\sqrt[p]{\\sum_{i=1}^n{(\\mid x_i - y_i \\mid)^p}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN算法brute-force实现\n",
    "\n",
    "计算预测样本到所有训练样本的距离，然后排序，选出距离最近的K个训练样本用于预测\n",
    "\n",
    "训练样本量较大时，算法效率较低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN算法KDTree实现\n",
    "\n",
    "先对训练样本"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
